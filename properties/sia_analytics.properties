# Which dataset to process
dataset.name = MERRA2
# Which collection from the dataset to process
collection.name = inst1_2d_int_Nx
# Name of the job
job.name = my_job
# Data input path on hdfs
input.path = /Users/feihu/Documents/Data/Merra2/daily
#input.path = /Users/feihu/Documents/Data/merra2_bigfile
# Data output path (where to store the results)
output.path = /Users/feihu/Desktop/sia_output/
# Hibernate xml file location
# xml.hibernate.table.mapping.file.path = merra2_entity_map.hbm.xml
# Names of variables ot build indices for
variable.names = KE
# Sets parallelism, more files per mapper is less parallelism
# files.per.map.task = 7
# File extension of the collection
file.extension = nc4
# Below can be one of local, classic, or yarn
mapreduce.framework.name = local
# Number of reduces to user when processing
# number.reducers = 1
# Threads per node (number of yarn containers)
threads.per.node = 10

analytics.operation = Aavg

# Spatiotemporal filtering parameters
year.start = 1980
year.end = 1980
month.start = 01
month.end = 01
day.start = 2
day.end = 2
hour.start = 0
hour.end = 0
height.start = -1
height.end = -1
lat.start = 0
lat.end = 1
lon.start = 0
lon.end = 0

hibernate.connection.driver_class = org.postgresql.Driver
hibernate.connection.url = jdbc:postgresql://localhost:5432/sia_test
hibernate.connection.username = feihu
hibernate.connection.password = feihu
hibernate.dialect = org.hibernate.dialect.PostgreSQL9Dialect
hibernate.hbm2ddl.auto = update