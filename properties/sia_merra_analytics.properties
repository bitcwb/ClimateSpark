# Which dataset to process
dataset.name = MERRA
# Which collection from the dataset to process
collection.name = tavg1_2d_int_Nx
# Name of the job
job.name = my_job
# Data input path on hdfs
#input.path = /Users/feihu/Documents/Data/Merra4D
input.path = /Users/feihu/Documents/Data/Merra1.5GB
# Data output path (where to store the results)
output.path = /Users/feihu/Desktop/output
# Hibernate xml file location
xml.hibernate.table.mapping.file.path = /Users/feihu/Documents/IDEAProjects/sia/sia-parent/sia-core/src/main/resources/merra_entity_map.hbm.xml
# Names of variables ot build indices for
variable.names = CUCNVRN
# Sets parallelism, more files per mapper is less parallelism
files.per.map.task = 7
# File extension of the collection
file.extension = hdf
# Below can be one of local, classic, or yarn
mapreduce.framework.name = local
# Number of reduces to user when processing
number.reducers = 1
# Threads per node (number of yarn containers)
threads.per.node = 10

analytics.operation = Aavg

# Spatiotemporal filtering parameters
year.start = 2000
year.end = 2016
month.start = 01
month.end = 03
day.start = 01
day.end = 31
hour.start = 0
hour.end = 23
height.start = -1
height.end = -1
lat.start = 0
lat.end = 160
lon.start = 0
lon.end = 139