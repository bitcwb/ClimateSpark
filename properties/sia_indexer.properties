# Which dataset to process
dataset.name = MERRA2
# Which collection from the dataset to process
#collection.name = tavgM_2d_mld_Nx
collection.name = inst1_2d_int_Nx
# Name of the job
job.name = my_job
# Data input path on hdfs
#input.path = /Users/feihu/Documents/Data/Merra4D
input.path = /Users/feihu/Documents/Data/Merra2/daily
#input.path = /Users/feihu/Documents/Data/merra2_bigfile
# Data output path (where to store the results)
output.path = /Users/feihu/Desktop/sia_output/

# Names of variables ot build indices for
variable.names = KE
# Sets parallelism, more files per mapper is less parallelism
files.per.map.task = 7
# File extension of the collection
file.extension = nc4
# Below can be one of local, classic, or yarn
mapreduce.framework.name = local

hibernate.connection.driver_class = org.postgresql.Driver
hibernate.connection.url = jdbc:postgresql://localhost:5432/sia_test
hibernate.connection.username = feihu
hibernate.connection.password = feihu
hibernate.dialect = org.hibernate.dialect.PostgreSQL9Dialect
hibernate.hbm2ddl.auto = update




